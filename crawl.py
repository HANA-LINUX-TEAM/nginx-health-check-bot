# crawl.py
import os
import requests
from bs4 import BeautifulSoup
from datetime import datetime

try:
    res = requests.get(f"http://{os.environ['SERVER_IP']}/index.html", timeout=5)
    if res.status_code != 200:
        raise Exception(f"ì‘ë‹µ ì½”ë“œ: {res.status_code}")
    soup = BeautifulSoup(res.text, "html.parser")
    info = soup.find("h1")
    text = info.text.strip() if info else "(<h1> ì—†ìŒ)"
except Exception as e:
    text = f"âŒ ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {str(e)}"

payload = {
    "text": f"**ğŸŒ nginx ì„œë²„ index.html ìƒíƒœ**\n\n- ë‚´ìš©: {text}\n- ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
}

requests.post(os.environ["WEBHOOK_URL"], json=payload)
